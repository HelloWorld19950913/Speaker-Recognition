# -*- coding: utf-8 -*-
"""UBM_feature_extraction(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fMuCyBNoLEj5tXmxFFffa123f9lxA7C1
"""
#_____________________________For Colab_____________________________#

# from google.colab import drive
# drive.mount('/content/drive', force_remount = True)

# !pip install PySoundFile
# !pip install librosa

#_____________________________----X----_____________________________#


#_____________________________Import Files_____________________________#

import os
import sys
from os.path import isdir, isfile, join
import numpy as np
import scipy
import scipy.fftpack as fft
from scipy.signal import get_window
import soundfile as sf
from sklearn.mixture import BayesianGaussianMixture
from sklearn.mixture import GaussianMixture
from sklearn.externals import joblib

#_____________________________----X----_____________________________#


#_____________________________Start of MFCC_____________________________#


# def frame_audio(audio, FFT_size, hop_size, sample_rate):
#     # hop_size in ms
    
#     audio = np.pad(audio, int(FFT_size / 2), mode='reflect')
#     frame_len = np.round(sample_rate * hop_size / 1000).astype(int)
#     frame_num = int((len(audio) - FFT_size) / frame_len) + 1
#     frames = np.zeros((frame_num,FFT_size))
    
#     for n in range(frame_num):
#         frames[n] = audio[n*frame_len:n*frame_len+FFT_size]
    
#     return frames

# def freq_to_mel(freq):
#     return 2595.0 * np.log10(1.0 + freq / 700.0)

# def met_to_freq(mels):
#     return 700.0 * (10.0**(mels / 2595.0) - 1.0)

# def get_filters(filter_points, FFT_size):
#     filters = np.zeros((len(filter_points)-2,int(FFT_size/2+1)))
    
#     for n in range(len(filter_points)-2):
#         filters[n, filter_points[n] : filter_points[n + 1]] = np.linspace(0, 1, filter_points[n + 1] - filter_points[n])
#         filters[n, filter_points[n + 1] : filter_points[n + 2]] = np.linspace(1, 0, filter_points[n + 2] - filter_points[n + 1])
    
#     return filters


# def get_filter_points(fmin, fmax, mel_filter_num, FFT_size, sample_rate):
#     fmin_mel = freq_to_mel(fmin)
#     fmax_mel = freq_to_mel(fmax)
    
#     print("MEL min: {0}".format(fmin_mel))
#     print("MEL max: {0}".format(fmax_mel))
    
#     mels = np.linspace(fmin_mel, fmax_mel, num=mel_filter_num+2)
#     freqs = met_to_freq(mels)
    
#     return np.floor((FFT_size + 1)*freqs / sample_rate).astype(int), freqs

# def dct(dct_filter_num, filter_len):
#     basis = np.empty((dct_filter_num,filter_len))
#     basis[0, :] = 1.0 / np.sqrt(filter_len)
    
#     samples = np.arange(1, 2 * filter_len, 2) * np.pi / (2.0 * filter_len)

#     for i in range(1, dct_filter_num):
#         basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / filter_len)
        
#     return basis

# def mfcc ( audio, sample_rate, FFT_size, hop_size = 15, mel_filter_num = 10, dct_filter_num = 40) :


#     audio_framed = frame_audio(audio, FFT_size=FFT_size, hop_size=hop_size, sample_rate=sample_rate)
#     window = get_window("hann", FFT_size, fftbins=True)
#     audio_win = audio_framed * window
#     audio_winT = np.transpose(audio_win)
#     audio_fft = np.empty((int(1 + FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F')

#     for n in range(audio_fft.shape[1]):
#         audio_fft[:, n] = fft.fft(audio_winT[:, n], axis=0)[:audio_fft.shape[0]]

#     audio_fft = np.transpose(audio_fft)
#     audio_power = np.square(np.abs(audio_fft))
    
#     freq_min = 0
#     freq_high = sample_rate / 2
#     filter_points, mel_freqs = get_filter_points(freq_min, freq_high, mel_filter_num, FFT_size, sample_rate=sample_rate)

#     filters = get_filters(filter_points, FFT_size)

#     enorm = 2.0 / (mel_freqs[2:mel_filter_num+2] - mel_freqs[:mel_filter_num])
#     filters *= enorm[:, np.newaxis]

#     audio_filtered = np.dot(filters, np.transpose(audio_power))
#     audio_log = 10.0 * np.log10(audio_filtered)

#     dct_filters = dct(dct_filter_num, mel_filter_num)

#     cepstral_coefficents = np.dot(dct_filters, audio_log)

#     return cepstral_coefficents

#_____________________________End of MFCC_____________________________#

#_____________________________Util Functions_____________________________#


#---------------------------------savenp---------------------------------#

def savenp ( arr , filename, Path = "" ):
    if type(arr).__module__ is not np.__name__:
        #print("Array provided to save not of the type numpy, trying to convert into numpy array")
        arr = np.array(arr)
        #print("Successfully converted!!")

    np.save( join(Path, filename) , arr)
    print("np array provided is saved at/as " + join(Path, filename))
    return



#---------------------------------RemoveNoise---------------------------------#
# Needs Work
# def RemoveNoise ( y, scale = 20 ) :

# 	mean = np.mean(y)

# 	for x in range(len(y)):
# 		if y[x] < mean/scale:
# 			y[x] = 0

#---------------------------------normalize---------------------------------#

def normalize ( arr ) :
	mx = np.max(abs(arr))
	if mx == 1:
		return arr
	return arr/mx

#---------------------------------savenp---------------------------------#

def savenp ( arr , filename, Path = "" ):
	if type(arr).__module__ is not np.__name__:
		#print("Array provided to save not of the type numpy, trying to convert into numpy array")
		arr = np.array(arr)
		#print("Successfully converted!!")

	np.save( join(Path, filename) , arr)
	print("np array provided is saved as " + filename)

#---------------------------------loadnp---------------------------------#

def loadnp ( filename, Path = "" ):
	if not filename.endswith(".npy"):
		filename = filename + ".npy"
	return np.load(join(Path , filename))

#---------------------------------ListAllFiles---------------------------------#

def ListAllFiles ( myPath = "", Extention = "wav" ):



	filePaths = []

	for root, dirs, files in os.walk(myPath) :
		for file in files:
			if file.endswith(Extention):
				filePaths.append(join(root, file))

	return filePaths

#---------------------------------FitGMM---------------------------------#

def FitGMM ( n_components, features, covariance_type = "full", tol = .001, verbose = 2 ,max_iter=100, n_init=1, warm_start=False, verbose_interval = 10):

	if type(features).__module__ is not np.__name__ :
		raise TypeError("features should be of type numpy")

	gmm = GaussianMixture( n_components = n_components, covariance_type = covariance_type, tol = tol, verbose = verbose, n_init = n_init, warm_start = warm_start, verbose_interval = verbose_interval  )
	gmm.fit( features )

	if gmm.converged_ == True :
		return gmm.weights_ , gmm.means_, gmm.covariances_, n_iter_
	else :
		print("GMM did not converge, either increase max_iter or set warm_start = True")
		sys.exit()		

#---------------------------------ReadAudio---------------------------------#

def ReadAudio ( filename, Path = "") :

	filepath = join(Path, filename)
	audio, sample_rate = sf.read( filepath )
	return audio, sample_rate

#---------------------------------ThresholdIndex---------------------------------#

def ThresholdIndex ( audio, threshold) :
  for x in range(len(audio)):
    if audio[x]>threshold :
      return x

#_____________________________----X----_____________________________#


#_____________________________Feature Extraction_____________________________#

# outfile = "drive/My Drive/"

# FilesPath = "drive/My Drive/Unpacked/"

# Files = ListAllFiles( myPath = FilesPath, Extention ="WAV" )
# print("Files")
# print(Files)
# print("End")

# print(len(Files))

# threshold = 0.03
# lenFiles = len(Files)
# audiolist = []
# sample_rates = []
# for x in range(lenFiles):
#   audio, sample_rate = ReadAudio( Files[x] )
#   audio = audio/audio.max()
#   left = ThresholdIndex( audio, threshold )
#   right = ThresholdIndex ( np.flip(audio), threshold )
#   audiolist.append(audio[left:-(right+1)])
#   sample_rates.append(sample_rate)

# for x in range(lenFiles):
#   feature = librosa.feature.mfcc(y = audiolist[x], sr = sample_rates[x], n_mfcc = 26)
#   savenp( arr = feature, filename = outfile + "NewLibrosaFeatures/features" + str(x))
#   print("done" + str(x))

# FeatureFiles = ListAllFiles("drive/My Drive/NewLibrosaFeatures", Extention = "npy")

# stack = loadnp(FeatureFiles[0]).transpose()[:, 1:13]
# FeatureFiles.remove(FeatureFiles[0])
# lenFeatureFiles = len(FeatureFiles)
# for x in range(lenFeatureFiles) :
#   feature = loadnp(FeatureFiles[x]).transpose()
#   print(feature.shape)
#   stack = np.concatenate((stack, feature[:, 1:13]),)
# print(stack.shape)

#_____________________________----X----_____________________________#

'''
****************
For testing we load the testing stack 
which is on the name of featurelist2.npy
****************
'''

drive_feature_path = "drive/My Drive/Corrected Params/featurelist.npy"
local_feature_test_path = "/home/srinath/Desktop/SpeakerRecognition/FeatureStack/featurelist2.npy"

'''
****************
Using local_feature_test_path
instead of drive_feature_path
****************
'''
stack = loadnp(local_feature_test_path)
print(stack.shape)

gmm = GaussianMixture(n_components = 200, max_iter = 1000, verbose = 2,  covariance_type='diag', warm_start = True, tol = 5)
#gmm = clf2
gmm.fit(stack)

means = gmm.means_
covars = gmm.covariances_
weights = gmm.weights_

if gmm.converged_ == False :
	gmm.fit(stack)
	means = gmm.means_
	covars = gmm.covariances_
	weights = gmm.weights_
	# savenp(means, "drive/My Drive/means")
	# savenp(covars, "drive/My Drive/covars")
	# savenp(weights, "drive/My Drive/weights")



'''
****************
For testing we are using local_filename
instead of filename
****************
'''
filename = 'drive/My Drive/Corrected Params/GMM_Converged.joblib.pkl'
local_filename = "/home/srinath/Desktop/SpeakerRecognition/UBM_DATA/test_GMM.joblib.pkl"

_ = joblib.dump(gmm, local_filename, compress=9)


'''
****************
Testing by loading the gmm again
****************
'''
gmm_test = joblib.load(local_filename)
print(gmm_test.converged_)
print(gmm_test.means_.shape)

print(gmm_test.predict(stack)[1:10])

